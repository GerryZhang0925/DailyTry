{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# チューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not show warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# matplotlib for japanese support\n",
    "import japanize_matplotlib\n",
    "\n",
    "# functions for data frame display\n",
    "from IPython.display import display\n",
    "\n",
    "# Adjust display options\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "plt.rcParams[\"font.size\"]=14\n",
    "random_seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. アルゴリズム選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(512, 30)\n",
      "(57, 30)\n",
      "score: 0.9649 LogisticRegression\n",
      "score: 0.8947 SVC\n",
      "score: 0.9474 DecisionTreeClassifier\n",
      "score: 0.9298 RandomForestClassifier\n",
      "[12:20:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "score: 0.9825 XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "x = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                                    test_size=test_size, random_state=random_seed,\n",
    "                                                    stratify=y)\n",
    "print(x.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# Linear Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algorithm1 = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "algorithm2 = SVC(kernel='rbf', random_state=random_seed)\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algorithm3 = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "algorithm4 = RandomForestClassifier(random_state=random_seed)\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "algorithm5 = XGBClassifier(random_state=random_seed)\n",
    "\n",
    "# Make a list of algorithm\n",
    "algorithms = [algorithm1, algorithm2, algorithm3, algorithm4, algorithm5]\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    algorithm.fit(x_train, y_train)\n",
    "    score = algorithm.score(x_test, y_test)\n",
    "    name = algorithm.__class__.__name__\n",
    "    print(f'score: {score:.4f} {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ハイパーパラメータの最適化\n",
    "　SVMのパラメータであるgammaとＣについて最適値を求める。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=123, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n"
     ]
    }
   ],
   "source": [
    "algorithm = SVC(kernel='rbf', random_state=random_seed)\n",
    "print(algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.6316 gamma: 1\n",
      "score: 0.6316 gamma: 0.1\n",
      "score: 0.6316 gamma: 0.01\n",
      "score: 0.9474 gamma: 0.001\n",
      "score: 0.9474 gamma: 0.0001\n",
      "score: 0.9474 gamma: 1e-05\n"
     ]
    }
   ],
   "source": [
    "# Find gamma value\n",
    "gammas = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "for gamma in gammas:\n",
    "    algorithm = SVC(kernel='rbf', gamma=gamma, random_state=random_seed)\n",
    "    algorithm.fit(x_train, y_train)\n",
    "    score = algorithm.score(x_test, y_test)\n",
    "    print(f'score: {score:.4f} gamma: {gamma}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9474 C: 1\n",
      "score: 0.9298 C: 10\n",
      "score: 0.9298 C: 100\n",
      "score: 0.9298 C: 1000\n",
      "score: 0.9298 C: 10000\n"
     ]
    }
   ],
   "source": [
    "# Find C value\n",
    "Cs = [1, 10, 100, 1000, 10000]\n",
    "for C in Cs:\n",
    "    algorithm = SVC(kernel='rbf', gamma=0.001, C=C, random_state=random_seed)\n",
    "    algorithm.fit(x_train, y_train)\n",
    "    score = algorithm.score(x_test, y_test)\n",
    "    print(f'score: {score:.4f} C: {C}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 交差検定法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均スコア:0.9141 個別スコア:[0.8889 0.9181 0.9353]\n"
     ]
    }
   ],
   "source": [
    "algorithm = SVC(kernel='rbf', random_state=random_seed, gamma=0.001, C=1)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stratifiedkfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(algorithm, x_train, y_train, cv=stratifiedkfold)\n",
    "\n",
    "mean = scores.mean()\n",
    "\n",
    "print(f'平均スコア:{mean:.4f} 個別スコア:{scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均スコア:0.9473 個別スコア:[0.9415 0.9474 0.9529] LogisticRegression\n",
      "平均スコア:0.9141 個別スコア:[0.8889 0.9181 0.9353] SVC\n",
      "平均スコア:0.9062 個別スコア:[0.8713 0.9415 0.9059] DecisionTreeClassifier\n",
      "平均スコア:0.9629 個別スコア:[0.9649 0.9591 0.9647] RandomForestClassifier\n",
      "[13:27:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:27:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:27:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "平均スコア:0.9570 個別スコア:[0.9474 0.9649 0.9588] XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "# Use cross validation to select algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algorithm1 = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "algorithm2 = SVC(kernel='rbf', random_state=random_seed, gamma=0.001, C=1)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algorithm3 = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "algorithm4 = RandomForestClassifier(random_state=random_seed)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "algorithm5 = XGBClassifier(random_state=random_seed)\n",
    "algorithms = [algorithm1, algorithm2, algorithm3, algorithm4, algorithm5]\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stratifiedkfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "for algorithm in algorithms:\n",
    "    scores = cross_val_score(algorithm, x_train, y_train,\n",
    "                             cv=stratifiedkfold)\n",
    "    score = scores.mean()\n",
    "    name = algorithm.__class__.__name__\n",
    "    print(f'平均スコア:{score:.4f} 個別スコア:{scores} {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. グリッドサーチ ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1e-05, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=123, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "       'C':[1, 10, 100, 1000, 10000],\n",
    "       'gamma':[1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "}\n",
    "algorithm = SVC(random_state=random_seed)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stratifiedkfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(algorithm, params, cv=stratifiedkfold)\n",
    "gs.fit(x_train, y_train)\n",
    "\n",
    "best = gs.best_estimator_\n",
    "best_pred = best.predict(x_test)\n",
    "print(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スコア: 0.9825\n",
      "\n",
      "混同行列\n",
      "[[20  1]\n",
      " [ 0 36]]\n"
     ]
    }
   ],
   "source": [
    "score = best.score(x_test, y_test)\n",
    "print(f'スコア: {score:.4f}')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print()\n",
    "print('混同行列')\n",
    "print(confusion_matrix(y_test, best_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
